{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Mount Google Drive and unzip the files\n",
    "from google.colab import drive\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define decompression path and destination path\n",
    "zip_path = '/content/drive/My Drive/Terrace/image_label.zip'\n",
    "extract_path = '/content/image'\n",
    "\n",
    "# unzip the files\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"File decompression completeï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Image standardisation and conversion\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the image folder path and the output folder path \n",
    "image_folder_path = '/content/image/'\n",
    "output_folder_path = '/content/image_label_trans'\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Define image standardisation and conversion\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(10), # Random rotation\n",
    "    transforms.ColorJitter(brightness=0.1), # Enhancement of brightness\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Get a list of image paths\n",
    "def get_image_paths(root_folder):\n",
    "    image_paths = []\n",
    "    for dirpath, _, filenames in os.walk(root_folder):\n",
    "        for fname in filenames:\n",
    "            if fname.endswith('.jpg') or fname.endswith('.png'):\n",
    "                image_paths.append(os.path.join(dirpath, fname))\n",
    "    return image_paths\n",
    "\n",
    "image_paths = get_image_paths(image_folder_path)\n",
    "\n",
    "# Process and standardise all image counters\n",
    "processed_count = 0\n",
    "\n",
    "# Process and standardise all images\n",
    "for image_path in image_paths:\n",
    "    # Load image\n",
    "    image = Image.open(image_path)\n",
    "    # Process and standardise images\n",
    "    processed_image = transform(image)\n",
    "    processed_image = processed_image.float().clamp(min=0, max=1)\n",
    "    # Calculate the relative path of the save path\n",
    "    relative_path = os.path.relpath(image_path, image_folder_path)\n",
    "    save_path = os.path.join(output_folder_path, relative_path)\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    # Save the standardised image to a new directory, keeping the filename unchanged\n",
    "    transforms.ToPILImage()(processed_image).save(save_path)\n",
    "    # Update Processing Counter\n",
    "    processed_count += 1\n",
    "\n",
    "print(f\"A total of {processed_count} photos were processed and saved in the folder: {output_folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Randomly select an image to display\n",
    "random_image_path = random.choice(image_paths)\n",
    "random_image = Image.open(random_image_path)\n",
    "processed_random_image = transform(random_image)\n",
    "processed_random_image = processed_random_image.float().clamp(min=0, max=1)\n",
    "processed_random_image_np = processed_random_image.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Display randomly selected normalised images\n",
    "plt.imshow(processed_random_image_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. data loading and segmentation\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(output_folder_path, transform=transform)\n",
    "batch_size = 32 \n",
    "\n",
    "# Calculate the number of samples in each category\n",
    "class_counts = [0] * len(dataset.classes)\n",
    "for _, label in dataset.samples:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "# Calculate weights for each category\n",
    "class_weights = [1.0 / count for count in class_counts]\n",
    "\n",
    "# Create a list of weights for sampling by category\n",
    "weights = [class_weights[label] for _, label in dataset.samples]\n",
    "\n",
    "# Delineate training, validation and test sets\n",
    "train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=0.2, stratify=dataset.targets)\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.2, stratify=[dataset.targets[i] for i in train_idx])\n",
    "\n",
    "# Create weight sampler for training set\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "\n",
    "# Create the data loader\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset = Subset(dataset, val_idx)\n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Model construction and modification\n",
    "from torchvision.models import efficientnet_b3\n",
    "\n",
    "model = efficientnet_b3(weights='IMAGENET1K_V1')\n",
    "num_ftrs = model.classifier[-1].in_features \n",
    "\n",
    "# Replace the last fully-connected layer and change the output category to 7 classes\n",
    "model.classifier = nn.Linear(num_ftrs, 7)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define loss function and optimiser (L2 regularisation)\n",
    "num_epochs = 10 \n",
    "learning_rate = 0.00001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# Add learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: train the model and save the model for each epoch\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            data_loader = train_loader if phase == 'train' else val_loader\n",
    "\n",
    "            for inputs, labels in data_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(data_loader.dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Save the model for each Epoch\n",
    "            save_path = f'/content/drive/My Drive/Terrace/model_terrace/model_epoch_{epoch}.pth'\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved for epoch {epoch} at {save_path}\")\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        # Scheduler update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# Training models\n",
    "model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate the model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, criterion, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(data_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(data_loader.dataset)\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print('Test Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "    print('Precision: {:.4f} Recall: {:.4f} F1: {:.4f}'.format(precision, recall, f1))\n",
    "\n",
    "# Evaluate each model\n",
    "for epoch in range(num_epochs):\n",
    "    model_path = f\"/content/drive/My Drive/Terrace/model_terrace/model_epoch_{epoch}.pth\"\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f\"Evaluating model from epoch {epoch}\")\n",
    "    evaluate_model(model, criterion, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Image\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define the decompression function\n",
    "def extract_zip(zip_path, extracted_folder_base):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_folder_base)\n",
    "\n",
    "# Recursively traverse the directory to count the number of images in all subfolders\n",
    "def count_images_in_folder(folder_path):\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        count += len([file for file in files if file.endswith('.jpg')])\n",
    "    return count\n",
    "\n",
    "# Unzip the specified zip to the corresponding folder and count the number of images unzipped\n",
    "zip_file_path = \"/content/drive/My Drive/Terrace/image_size.zip\"\n",
    "extracted_folder_base = \"/content/images_size/\"\n",
    "\n",
    "os.makedirs(extracted_folder_base, exist_ok=True)\n",
    "\n",
    "# Unzip the package\n",
    "extract_zip(zip_file_path, extracted_folder_base)\n",
    "\n",
    "# Statistics on the number of images unpacked\n",
    "extracted_count = count_images_in_folder(extracted_folder_base)\n",
    "\n",
    "print(f\"Extracted {extracted_count} images from '{zip_file_path}'.\")\n",
    "print(\"Image extraction completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Loading the model\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Loading models\n",
    "model_path = \"/content/drive/My Drive/Terrace/model_terrace/model_best.pth\" \n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model Prediction\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define data pre-processing\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define category index to name mapping\n",
    "class_idx_to_name = {\n",
    "    0: 'activities',\n",
    "    1: 'food',\n",
    "    2: 'indoors',\n",
    "    3: 'landscape',\n",
    "    4: 'posing',\n",
    "    5: 'species',\n",
    "    6: 'structures'\n",
    "}\n",
    "\n",
    "# Define dataset classes\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, os.path.basename(img_path)\n",
    "\n",
    "# Path to the folder where the CSV is saved\n",
    "csv_save_folder = \"/content/drive/My Drive/Terrace/result_csv/\"\n",
    "\n",
    "# Iterate through each subfolder after unpacking, make a prediction and save the result as CSV\n",
    "for folder in os.listdir(extracted_folder_base):\n",
    "    folder_path = os.path.join(extracted_folder_base, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.jpg')]\n",
    "\n",
    "        dataset = CustomDataset(image_files, transform=data_transforms)\n",
    "        data_loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "        # Predicted and saved as CSV\n",
    "        predictions = []\n",
    "        image_names = []\n",
    "        for inputs, filenames in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend([class_idx_to_name[pred.item()] for pred in preds])\n",
    "            image_names.extend(filenames)\n",
    "\n",
    "        results_df = pd.DataFrame({'Image': image_names, 'Category': predictions})\n",
    "        csv_name = os.path.join(csv_save_folder, f'{folder}_predictions.csv')\n",
    "        results_df.to_csv(csv_name, index=False)\n",
    "\n",
    "        print(f\"Saved predictions for folder '{folder}' to {csv_name}\")\n",
    "\n",
    "print(\"Prediction and CSV saving complete.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
